{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**\n",
    "1. Change Subject Code in first cell, Select this cell and run \"Run all below selected cell\"\n",
    "2. Allow program to fully run then SAVE THE FILE\n",
    "3. Run these commands to get HTML File of Report \n",
    "export SUBJECT = subject code\n",
    "jupyter nbconvert --to html --no-input Courier_Report_v2.ipynb --output $SUBJECT\\_courier_report.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'available_if' from 'sklearn.utils.metaestimators' (/home1/noaherz/.conda/envs/cml3/lib/python3.7/site-packages/sklearn/utils/metaestimators.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5c674e1dd9e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpolar\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcircular_hist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mreportlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpagesizes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mletter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/noaherz/.conda/envs/cml3/lib/python3.7/site-packages/polar/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpolar\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/noaherz/.conda/envs/cml3/lib/python3.7/site-packages/polar/polar.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBalancedRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/noaherz/.conda/envs/cml3/lib/python3.7/site-packages/imblearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcombine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/noaherz/.conda/envs/cml3/lib/python3.7/site-packages/imblearn/ensemble/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_easy_ensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEasyEnsembleClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_bagging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBalancedBaggingClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_forest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBalancedRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/noaherz/.conda/envs/cml3/lib/python3.7/site-packages/imblearn/ensemble/_easy_ensemble.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_docstring\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_random_state_docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_deprecate_positional_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mMAX_INT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/noaherz/.conda/envs/cml3/lib/python3.7/site-packages/imblearn/pipeline.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetaestimators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mavailable_if\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'available_if' from 'sklearn.utils.metaestimators' (/home1/noaherz/.conda/envs/cml3/lib/python3.7/site-packages/sklearn/utils/metaestimators.py)"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import cmlreaders as cml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "plt.rcParams['savefig.facecolor']='white'\n",
    "from matplotlib.collections import LineCollection\n",
    "from adjustText import adjust_text\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None\n",
    "import pandas_to_pybeh as pp\n",
    "import scipy as scp\n",
    "from scipy.spatial import distance\n",
    "from polar import circular_hist\n",
    "import os\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen.canvas import Canvas\n",
    "from reportlab.lib.utils import ImageReader\n",
    "import matplotlib.image as mpimg\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'reset_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-64e6089dbc32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mfull_evs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfull_evs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfull_evs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# only real delivery days\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mfull_evs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_evs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'reset_index'"
     ]
    }
   ],
   "source": [
    "sub = 'R1620J'#INSERT SUBJECT ID HERE\n",
    "\n",
    "data = cml.get_data_index(kind = 'r1'); data = data[data['experiment'] =='DBOY1']\n",
    "\n",
    "data = data[data['subject']==sub]\n",
    "\n",
    "full_evs = None\n",
    "for i, row in data.iterrows():\n",
    "    read = cml.CMLReader(subject=row['subject'], experiment=row['experiment'], session=row['session'])\n",
    "    evs = read.load('task_events')\n",
    "    full_evs = evs if full_evs is None else full_evs.append(evs)\n",
    "# only real delivery days\n",
    "full_evs = full_evs.reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    Markdown(\n",
    "        '# '+sub + ' Courier Report'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test EEG (assumes bipolar)\n",
    "pairs = read.load('pairs')\n",
    "pres = evs[evs.type=='WORD']\n",
    "eeg = read.load_eeg(pres, scheme=pairs, rel_start=-500, rel_stop=500).to_ptsa()\n",
    "plt.plot(eeg.time, eeg.values[pres.recalled.astype(bool)].mean((0, 1))-eeg.values[~pres.recalled.astype(bool)].mean((0, 1)))\n",
    "plt.xlabel('time')\n",
    "directory = sub\n",
    "display(\n",
    "    Markdown(\n",
    "        '#### EEG Data Check'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres = full_evs[full_evs.type=='WORD']\n",
    "cuerec = full_evs[full_evs.type=='CUED_REC_WORD']\n",
    "cue = full_evs[full_evs.type=='CUED_REC_CUE']\n",
    "final = full_evs[full_evs.type=='FFR_REC_WORD']\n",
    "storerec = full_evs[full_evs.type=='SR_REC_WORD']\n",
    "\n",
    "recalls = [full_evs.loc[i, \"item\"]==full_evs.loc[i+1, \"item\"] for i in cue.index.values]\n",
    "immediate_recalls = pres['recalled']\n",
    "srRate = sum([len(storerec[(storerec.intrusion==0)&(storerec.session==i)].item.unique()) for i in storerec.session.unique()])/sum([len(pres[pres.session==i].store.unique()) for i in pres.session.unique()])\n",
    "ffr = np.hstack([np.isin(pres[pres.session==i].item, final[final.session==i].item.unique()) for i in full_evs.session.unique()])\n",
    "\n",
    "rates_df = pd.DataFrame({'Recall': [\"Cued Recall\", \"Immediate FR\", \"Store FR\", \"Final FR\"], \"Rate (%)\": [np.mean(recalls), np.mean(immediate_recalls), srRate, np.mean(ffr)]})\n",
    "rates_df.iloc[:, 1] = np.round(rates_df.iloc[:, 1]*100, 2)\n",
    "rates_html = rates_df.to_html()\n",
    "\n",
    "display(\n",
    "    Markdown(\n",
    "        '#### Recall Rates'\n",
    "    )\n",
    ")\n",
    "rates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointing_tasks = full_evs[full_evs.type == 'pointing finished']\n",
    "err_angles = np.radians((pointing_tasks.correctPointingDirection - pointing_tasks.submittedPointingDirection)).values\n",
    "err_angles = (err_angles+np.pi) % (2*np.pi) - np.pi\n",
    "\n",
    "# correct for distribution of available stores\n",
    "# loc_evs = full_evs[(full_evs.storeX!=-999)&(full_evs.store!='-999')]\n",
    "# stores = loc_evs.groupby('store').agg('mean')[['storeX', 'storeZ']]\n",
    "# xstores = stores['storeX'].values; zstores = stores['storeX'].values\n",
    "# angular_range = []\n",
    "# for i, row in pointing_tasks.iterrows():\n",
    "#     # current player location\n",
    "#     xloc, zloc = row[['presX', 'presZ']]\n",
    "#     # distribution of angles from location to all stores\n",
    "#     angles = np.arctan((zloc-zstores)/(xloc-xstores))\n",
    "#     angles[xloc-xstores<0]+= np.pi\n",
    "#     angular_range.append(np.ptp(angles))\n",
    "# angular_range = np.array(angular_range)\n",
    "# # multiply errors by ratio of whole field to available angular distribution of stores\n",
    "# err_angles = err_angles * (2*np.pi)/ angular_range\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = plt.subplot(111, projection='polar')\n",
    "n, bins, _ = circular_hist(ax, err_angles, offset=np.pi/2, bins=30, ec='k', alpha=0.6)\n",
    "ax.vlines([np.mean(err_angles)+err_angles.std(), np.mean(err_angles)-err_angles.std()], ymin=0, ymax=np.max(n/err_angles.size/np.pi)**.5,\n",
    "         ls='--')\n",
    "ax.vlines(np.mean(err_angles),\n",
    "          ymin=0, ymax=np.max(n/err_angles.size/np.pi)**.5,\n",
    "         ls='--', colors='r')\n",
    "\n",
    "ax.set_title(r'Distibution of Pointing Errors ($\\sigma = {:.2f}$)'.format(err_angles.std()*180/np.pi), fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deliveries = full_evs[full_evs.type=='WORD']\n",
    "diff_times = np.insert(np.diff(full_evs.mstime), 0, 0)\n",
    "delivery_times = diff_times[full_evs.type == 'WORD']\n",
    "print('Median Delivery Time: {:.2f} seconds'.format(np.median(delivery_times)/1000))\n",
    "\n",
    "distX = np.insert(np.diff(deliveries.storeX), 0, deliveries.iloc[0].storeX)\n",
    "distZ = np.insert(np.diff(deliveries.storeZ), 0, deliveries.iloc[0].storeZ)\n",
    "dist = np.sqrt(distX**2 + distZ**2)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "p, resid, _, _, _= np.polyfit(dist, delivery_times/1000, 1, full=True)\n",
    "sns.scatterplot(dist, delivery_times/1000, alpha=.8)\n",
    "plt.xlabel('Euclidean Distance')\n",
    "plt.ylabel('Delivery Time (s)')\n",
    "vals = np.arange(np.min(dist), np.max(dist))\n",
    "plt.plot(vals, np.polyval(p, vals), 'k--')\n",
    "rmse = np.sqrt(np.mean((np.polyval(p, dist) - delivery_times/1000)**2))\n",
    "r2 = np.corrcoef(dist, delivery_times/1000)[0, 1]**2\n",
    "print(r'RMSE: {:.3f}, R^2: {:.3f}'.format(rmse, r2))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.xlabel('Delivery Times (s)')\n",
    "plt.hist(delivery_times/1000, alpha=.8)\n",
    "_ = plt.axvline(delivery_times.mean()/1000, 0, max(delivery_times/1000), c='k')\n",
    "display(\n",
    "    Markdown(\n",
    "        '#### Travel Time'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deliveries = full_evs[full_evs.type=='WORD']\n",
    "deliveries['pos'] = deliveries.groupby(['subject', 'session', 'trial']).cumcount()\n",
    "delivRecalls = deliveries.pivot_table(values = ['recalled'], index=['subject', 'session', 'trial'], columns='pos')\n",
    "\n",
    "recword = full_evs[full_evs.type=='REC_WORD']\n",
    "recword['pos'] = recword.groupby(['subject', 'session', 'trial']).cumcount()\n",
    "recallpos = recword.pivot_table(values = ['serialpos'], index=['subject', 'session', 'trial'], columns='pos')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(np.arange(1, 13), delivRecalls['recalled'].mean(), label = 'SPC')\n",
    "plt.xlabel('Serial Position')\n",
    "plt.ylabel('Recall Probability')\n",
    "listLength = 12\n",
    "pfr = np.zeros(listLength)\n",
    "for pos in recallpos['serialpos'].iloc[:, 0]:\n",
    "    if pos>0:\n",
    "        pfr[int(pos)-1]+=1\n",
    "    else:\n",
    "        continue\n",
    "pfr = pfr/len(recallpos)\n",
    "\n",
    "plt.plot(np.arange(1, listLength + 1), pfr, label = 'PFR')\n",
    "plt.legend()\n",
    "display(\n",
    "    Markdown(\n",
    "        '#### Serial Position Curve'\n",
    "    )\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_to_pybeh as pb\n",
    "\n",
    "# filter out lists with no recalls\n",
    "for i in full_evs.session.unique():\n",
    "    for j in full_evs.trial.unique():\n",
    "        word = full_evs[(full_evs.session==i)&(full_evs.trial==j)&(full_evs.type=='REC_WORD')]\n",
    "        if (len(word)==0)&(j>0):\n",
    "            full_evs.drop(full_evs[(full_evs.session==i)&(full_evs.trial==j)].index, inplace=True)\n",
    "\n",
    "full_evs['itemno'] = full_evs['item'].astype('category').cat.codes\n",
    "crp_df = full_evs.groupby(['subject']).apply(pb.pd_crp, itemno_column='itemno', \n",
    "                               list_index=['subject', 'session', 'trial'], \n",
    "                               lag_num=6).reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "crp = sns.pointplot(data=crp_df, x='lag', y='prob')\n",
    "_ = crp.set_title('Lag CRP')\n",
    "crp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    Markdown(\n",
    "        '#### Path Traveled'\n",
    "    )\n",
    ")\n",
    "for session in data['session'].unique():\n",
    "    print('Session %d' %session)\n",
    "    log = pd.read_json('/data/eeg/{}/behavioral/DBOY1/session_{}/session.jsonl'.format(sub, session), lines=True)\n",
    "    log = log[(log.type=='PlayerTransform')|(log.type=='object presentation begins')]\n",
    "\n",
    "    def extract_position(row):\n",
    "        if row.type=='PlayerTransform':\n",
    "            return (row['data']['positionX'], row['data']['positionY'], row['data']['positionZ'])\n",
    "        elif row.type=='object presentation begins':\n",
    "            return eval(row['data']['player position'])\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "    log['location']=log.apply(extract_position, axis=1)\n",
    "    log['trial']=log.apply(lambda row: row['data']['trial number'] if np.isin('trial number', list(row['data'].keys())) else np.nan, axis=1)\n",
    "    movements = log.fillna(method='pad').dropna()\n",
    "    sess_pos = np.stack(list(map(list, movements.location.values)))\n",
    "    \n",
    "    group_mov = movements.groupby('trial')\n",
    "    dd_list = np.array(list(group_mov.groups.keys())).astype(int)\n",
    "    pos_by_list = [np.stack(list(map(list, group_mov.get_group(i)['location']))) for i in dd_list]\n",
    "    fig, ax = plt.subplots(len(dd_list)//2+len(dd_list)%2, 2, figsize=(12, 5*(len(dd_list)//2+len(dd_list)%2)))\n",
    "    ax = ax.ravel()\n",
    "    for i, dd in enumerate(dd_list):\n",
    "        store_locs = log['data'][(log.type=='object presentation begins')&(log.trial==i)].apply(lambda json: eval(json['store position']))\n",
    "        store_names = log['data'][(log.type=='object presentation begins')&(log.trial==i)].apply(lambda json: json['store name'])\n",
    "        list_stores = np.stack(list(map(list, store_locs.values)))\n",
    "\n",
    "        points = np.array([pos_by_list[i][:, 0], pos_by_list[i][:, 2]]).T.reshape(-1, 1, 2)\n",
    "        segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "        lc = LineCollection(segments, cmap='hot')\n",
    "        # Set the values used for colormapping\n",
    "        lc.set_array(np.linspace(0, 1, len(segments)))\n",
    "        lc.set_linewidth(3); lc.set_alpha(.6)\n",
    "        line = ax[i].add_collection(lc)\n",
    "        ax[i].scatter(list_stores[:, 0], list_stores[:, 2])\n",
    "        texts = []\n",
    "        for x, y, name, order in zip(list_stores[:, 0], list_stores[:, 2], store_names, np.arange(len(store_names))):\n",
    "            texts.append(ax[i].text(x-5, y+5, name.capitalize() + ' ({})'.format(order)))\n",
    "        adjust_text(texts)\n",
    "        ax[i].set_title('DD %d' %dd, fontsize=14)\n",
    "        ax[i].set_xticklabels([]);ax[i].set_yticklabels([])\n",
    "    plt.tight_layout()\n",
    "    cbar = fig.colorbar(line, ax=ax[:], location='right', shrink = 0.5)\n",
    "    cbar.set_label('% of path')\n",
    "    fig.set_facecolor('white')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
